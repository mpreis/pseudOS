      +--------------------+
      |        CS 140      |
      | PROJECT 1: THREADS |
      |   DESIGN DOCUMENT  |
      +--------------------+
           
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Thomas Huetter <thomas.huetter@stud.sbg.ac.at>
Mario Preishuber <mario.preishuber@stud.sbg.ac.at>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

           ALARM CLOCK
           ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

New thread local variable:
    - uint64_t ticks_to_sleep;
Holds the number of ticks that the thread has to sleep.

To reduce the time spent in timer_interrupt () we have implemented a blocked_list, which is a static global variable in timer.c.
    - static struct list blocked_list;

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

At first we have to disable the interrupts, so that we can assure that 
the thread will be blocked. But before we have to save the old 
interrupt-level because we have to set it again after wake up. The number 
of ticks are stored for each thread in a thread-local variable and then 
the thread will be blocked. After the waking up, the thread sets its old 
interrupt-level again.


>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

As mentioned in A1, we have implemented a list that holds only blocked threads. Due to this, we do not have to iterate over all threads in every timer_interrupt. 

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

To avoid any race conditions, we decided to disable all interrupts during the timer_sleep () method. So, setting the number of ticks, insert it in the blocked_list and blocking the current thread will not get interrupted. 

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Answer like in A4.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

While choosing a uint64_t for the ticks is pretty obvious, we consider that a list is the perfect datastructe for collecting all blocked threads. Lists are already used for all threads and all ready threads, furthermore they are well implemented by Pintos itself.


       PRIORITY SCHEDULING
       ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Extensions of struct thread in thread.h:
  - struct list donations
    This list holds all donations of the thread.
    
  - struct list_elem donelem
    Element of the donation list.
    
  - struct lock *wanted_lock
    Thread is waiting for this lock.
    
New #define in thread.c:
  - #define MAX_DEPTH 8
    Represents the maximum detph of nested donation 
    (default = 8 as described in the documentation).

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Threads:
  TL ... A thread with low priority.
  TM ... A thread with medium priority.
  TH ... A thread widh high priority.
  
Locks: L1, L2

Current state:
  TL holds the lock of L1
  TM holds the lock of L2
  
  TM needs to lock L1
  TH needs to lock L2
  
  
Diagram:

+--- TH ----------+   +--- TM ---------------+   +--- TL ---------------+
| priority: TH1   |   | priority: max{TH,TM} |   | priority: max{TL,TM} |
| wanted_lock: L2 |-->| wanted_lock: L1      |-->| wanted_lock: NULL    |
| donations: NULL |   | donations: TH        |   | donations: TM        |
+-----------------+   +----------------------+   +----------------------+

L1:
 + holder: TL
 + waiters: TM

L2:
 + holder: TM
 + waiters: TH


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

If a lock is released, it is checked if there are any waiting threads.
Is a thread waiting, we sort the list of waiters and unblock the thread
with the highest priority.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

After calling lock_acquire we check if a thread holds the needed lock.

Is another thread (=holder) holding the lock, the variable wanted_lock 
of the current thread ist set to LOCK. Furthermore, the current thread 
adds a donation to the donations-list of the thread which holds the LOCK.
The priority of the holder is not changed yet.

The next step calls sema_down. Is the LOCK not available the method
thread_donate_priority is called. Now the lock holders priority is 
updated (also nested). The currrent thread adds itself to the 
waiters list of the lock and blocks.

If the thread gets the lock, it sets itself as holder and sets the 
wanted_lock variable to NULL.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

After calling lock_release the holder of the lock is set to NULL. 
The next step is to lookup for a donation and remove it. Then 
sema_up is called which checks the list of waiters. Are threads
waiting they get sorted. The thread with the highest priority
is unblocked. The last step is to execute thread_priority_check,
to check if there is a thread with a higher priority.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Race conditions can occur while reading or writing the priority of
the current thread. We avoid this be disabling interrupts.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We wanted to use as much as possible of the existing code. Furthermore,
we tried to keep our code simple. For example we use the existing 
implementation of list to realise multiple donations.

In the first version we used a global list of all locks. But during 
implementing priority donation we changed our concept. The most significant 
reasen therefor was, that it is much easier to implement priority donation 
if each thread knows the lock it is waiting for.


        ADVANCED SCHEDULER
        ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Extensions of struct thread in thread.h:
  - int niceness
    Holds the nice value of a thread.
    
  - int recent_cpu
    CPU time this thread has received recently.
    
Extensions of globals in thread.c:
  - int load_avg
    Average number of threads ready to run over the past minute.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59      A
 4      4   0   0  62  61  59      A
 8      8   0   0  61  61  59      B
12      8   4   0  61  60  59      A
16     12   4   0  60  60  59      B
20     12   8   0  60  59  59      A
24     16   8   0  59  59  59      C
28     16   8   4  59  59  58      B
32     16  12   4  59  58  58      A
36     20  12   4  58  58  58      C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

Yes. If there are one or more threads with sthe same priority as the
current running thread, it is not clear witch thread should run next.
One opportunity is to continue running the current thread. Another is
to yield the current running thread and execution a thread of the ready 
ones.

We decided to stop the current running thread and switch to the thread
of the ready list which was inserted first. 

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

We are doing the most parts of the scheduling algorithm inside the
interrupt context, because the calculation of recent_cpu, priority, etc.
have to be done in constant intervals. It is not necessary to do this
things every timer interrupt, so (as given from the documentation) we
have conditions to do it every second.
Also checking checking the blocked_list is very expensive. But due to
the seperate list we just have to iterate over all blocked threads
each interrupt.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Advantages:
  + All needed datastructes are given by the OS
  + Less extensions are requiered
  
Disadvantages:
  - Sorting the lists and/or inserting ordered is expansive
  - interrupts are also expensive
  
Future work:
  * Try to reduce the number of interrupts
  * Replace the ready list by an ready list for each priority

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

The fixed-point arithmetic is implemented in a seperate header file
called "fixed-point.h" as mentioned in the documentation.
We have decided to use inline functions. Functions are really handy
and clear. Because all functions are very short in terms of operations
(mostly just one equation), the compiler can replace the function calls
directly with the code in the function. This leads to a performance
optimization.

         SURVEY QUESTIONS
         ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?